<html><head></head><body><p>这次部署了一次量化后的模型，大概记录一下部署过程和遇到的问题。</p><p>因为显卡显存只有8G，所以部署的是6b的int4量化模型。</p><h2 id="部署"><a href="https://mxts.jiujiuer.xyz/2023/08/22/ChatGLM%E9%83%A8%E7%BD%B2%E6%89%8B%E8%AE%B0/#%E9%83%A8%E7%BD%B2" class="headerlink" title="部署"></a>部署</h2><p>一般是直接从Hugging Face克隆仓库下来。我当时担心速度不够从清华云盘下载的，不过后来克隆发现速度很快，一般应该是不用担心下载速度的。</p><p>首先克隆6b的仓库，然后进入仓库安装依赖：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/THUDM/ChatGLM-6B &amp;&amp; <span class="built_in">cd</span> ChatGLM-6B</span><br/><span class="line">pip install -r requirements.txt</span><br/></pre></td></tr></tbody></table></figure><p>然后下载ChatGLM-6B的模型的量化版本。注意，<strong>一定要下载所有的文件</strong>。如果clone不下来，就先把其他小文件下下来，然后在清华网盘下载模型本体：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://huggingface.co/THUDM/chatglm-6b-int4</span><br/><span class="line"><span class="comment"># 量化版本地址：https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/</span></span><br/></pre></td></tr></tbody></table></figure><p>完成后，更改cli-demo.py和webui-demo.py中的<code>THUDM/chatglm-6b-int4</code>为你本地的路径：<code>/path/to/chatglm-6b-int4</code>即可。</p><p>最后，使用python运行即可：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">python3 webui-demo.py</span><br/></pre></td></tr></tbody></table></figure><h2 id="问题"><a href="https://mxts.jiujiuer.xyz/2023/08/22/ChatGLM%E9%83%A8%E7%BD%B2%E6%89%8B%E8%AE%B0/#%E9%97%AE%E9%A2%98" class="headerlink" title="问题"></a>问题</h2><p>如果报错的话，可能是缺少 tokenizer 的相关文件：tokenizer_config.json、special_tokens_map.json、tokenization_chatglm.py 和 ice_text.model。将这些文件（位于你下载的模型的目录中）补全即可解决。</p></body></html>