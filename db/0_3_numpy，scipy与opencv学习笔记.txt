<html><head></head><body><h2 id="序"><a href="https://mxts.jiujiuer.xyz/2023/11/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#%E5%BA%8F" class="headerlink" title="序"></a>序</h2><p>这门课的研究思路很清晰，就是围绕标题，自底向上，借助数学工具，一步一步实现各种复杂的功能以及算法，最终一步步接近让计算机拥有“视觉”的目标。</p><p>首先是数据的表示，概念的抽象，如何用离散的数据去近似抽象的视觉这个概念。这个过程通过直观理解和数学工具，以及建模方法，为计算机视觉提供了一种可行的数学上的表示和运算方法：像素，以及基于像素的一系列运算，比如滤波，仿射变换，更高自由度的变换，基于像素颜色值的变换等等，以及由这一系列变换得到的图像特征。</p><p>其次，是研究在图像的像素模型下，利用数学方法去研究分析以及利用图像特征的方法。这其中，就有诸如角点检测，边缘检测，全景图拼接以及处理等命题。</p><h2 id="生成对抗网络GAN"><a href="https://mxts.jiujiuer.xyz/2023/11/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9CGAN" class="headerlink" title="生成对抗网络GAN"></a>生成对抗网络GAN</h2><p>通俗来说就是让两个网络作为对抗组，比如说生成图片的NN和鉴别图片的NN，两方轮流作为输入输出（也就是交替训练），在循环中不断提升两个网络的效果，最终达到生成内容以假乱真的效果。NN炼丹的关键是其中的loss函数设计，不过他们的做法是直接用另一个NN作为这个NN的loss函数来回馈训练效果。</p><p>目前比较突出的成果一个就是近几年的Stable Diffusion，算是这里边比较突出的一个了。这东西在图像的有损压缩里边用的也多，至于有损压缩的应用嘛，一般在一些需要使用算力去换带宽的场合很适用，比如卫星数据传输。其他应用就是图像的填充和补全，比如合理推测图像的缺失部分内容。另外就是，网络的输入不一定是噪声，输出也不一定是真假。改变其输入和输出的类型，可以赋予NN以不少是实用场景。</p><p>GAN的优点是效果好，比以前用的高斯模糊的效果都很好。但是问题也很突出，就是GAN很难训练。GAN的两方是生成器和判别器，训练的结果很大程度上与两方的能力是否足够接近有很大关系。</p><p>另外就是GAN的思想重点在对抗，并没有要求其他的条件。所以比如说可以有多个判别方，有多个生成方等。</p><h2 id="Attention-Is-All-You-Need"><a href="https://mxts.jiujiuer.xyz/2023/11/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#Attention-Is-All-You-Need" class="headerlink" title="Attention Is All You Need"></a>Attention Is All You Need</h2><p>注意力机制一开始是应用于机器翻译领域，通过一个合适的重点词语权重标注机制，让算法更有重点地提取概要。如今的GPT也很大程度上受到注意力机制的启发才产生了不断预测下一个词向量概率的朴素思想。</p><p>注意力机制可以理解成给分词加上权重。将一个句子进行分词作为一个向量，将这个词语向量通过Softmax这样的激活函数进行处理之后，再借助矩阵进行变换，从而得到处理后的，带有权重的词向量。处理后的词向量，权重总和为1。加权后的句子，再进行翻译，效果就会好很多了。</p><p>至于将Attention思想迁移到CV领域进行应用的方法，关键是将图像”语义化“。一个常用的方法是将图像分割，分割成小块，对每个小块采用相同的思想。这就是VIT（Vision Transformer）的思想。</p><h2 id="激活函数"><a href="https://mxts.jiujiuer.xyz/2023/11/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0" class="headerlink" title="激活函数"></a>激活函数</h2><h3 id="Softmax"><a href="https://mxts.jiujiuer.xyz/2023/11/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><p>Softmax函数是一种常用的激活函数,主要用于将多分类问题中的输出值转换为概率分布。在神经网络中,输出层通常使用softmax函数,将输出值转换为每个类别概率。</p><p>Softmax函数的定义如下:<br/>$$<br/>Softmax(x) = e^(x_i) / (e^(x_1) + e^(x_2) + … + e^(x_n))<br/>$$<br/>其中,x是一个K维向量,Softmax函数的输出也是一个K维向量,并且每个元素的范围都在0到1之间,并且所有元素的和为1。</p><p>在多分类问题中,假设输出层有K个神经元,每个神经元代表一个类别。Softmax函数的作用是将输出层的输出转换为每个类别对应的概率。例如,如果输出层输出为[1.2, 2.3, 3.1],则对应的概率为[0.21, 0.34, 0.45]。</p><p>Softmax函数可以解决输出值非常大的问题,因为它可以防止输出值过大而导致的梯度消失或梯度爆炸。此外,Softmax函数还可以进行归一化,使得概率和为1,使得概率分布更加合理。</p><h2 id="期末划重点咯"><a href="https://mxts.jiujiuer.xyz/2023/11/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#%E6%9C%9F%E6%9C%AB%E5%88%92%E9%87%8D%E7%82%B9%E5%92%AF" class="headerlink" title="期末划重点咯"></a>期末划重点咯</h2><blockquote><p><code>sudo 老师给我分</code></p></blockquote><p>有个压缩包，里边画红钩的都是重点</p><p>占比大概NN和传统方法4-6开</p><ul><li>Chap 1 没啥重点<ul><li>什么是光， 可见光谱的范围这些的</li><li>人的视觉系统这些概念啥的</li><li>三色光的相关内容</li></ul></li><li>Chap 3 重点<ul><li>灰度图（取值范围），RGB</li><li>图像两种基本运算</li><li>矩阵的运算</li><li>滤波概念，高斯滤波</li><li>卷积，点乘积，性质，计算过程strike, padding计算结果图像尺寸这些的</li></ul></li><li>Chap 4 边缘检测<ul><li>边缘定义,为啥是边缘</li><li>图像的梯度</li><li>噪声</li><li>边缘检测器：sobel算子,roberts算子,prewwit算子等</li><li>边缘存在的问题：噪声，拟合等</li></ul></li><li>Chap 6 图像插值<ul><li>线性插值，上下采样等，高斯金字塔</li><li>图像放大的插值算法（超分）<ul><li>最近邻，双线性，三次插值。不过现在都用GNN做超分了</li></ul></li></ul></li><li>Chap ? 特征匹配<ul><li>典型特征匹配计算方法</li><li>特征和特真不变性：啥特征的啥不变性 SIFT特征</li></ul></li><li>Chap 7 图像变换<ul><li>几种变换方式</li><li>线性变换：变灰度，变尺度等</li><li>按照变换剧烈程度递增：平移，旋转，仿射，投影</li><li>得记得变换矩阵的特征,大概得看明白</li></ul></li><li>Chap 8 图像配准 没啥讲的</li><li>Chap 11 单视图建模<ul><li>消失线和消失点等 得会计算</li></ul><ul><li>双试图立体视觉：视差和深度计算</li><li>窗口配准</li><li>极点极线极面</li><li>本质矩阵，基本矩阵是谁到谁的映射</li><li>深度估计</li></ul></li><li>Chap 14 图像三维重建<ul><li>一个相机转着拍 内参矩阵不变，为了配窗</li><li>重复的问题</li></ul></li><li>Chap 16 机器视觉<ul><li>激活函数和矩阵计算</li><li>神经网络结构</li><li>卷积网络的池化操作</li></ul><ul><li>反向传播：对w求导而非对x求导，而且得会算反向传播函数</li></ul></li><li>Chap 18 图像分割<ul><li>语义分割和实例分割</li><li>分割手段：边缘检测,聚类等方法</li></ul></li><li>Chap 19 目标检测与分类<ul><li>输出：中心型，边界型</li><li>两个方法：两步法，一步法（Yolo）</li></ul></li><li>Chap 21 实操<ul><li>玩玩pytorch</li></ul></li><li>Chap 23 神经网络前沿<ul><li>GAN</li><li>Attention(q,k,v)<ul><li>Softmax</li></ul></li></ul></li></ul></body></html>